<h1>From-Text-to-Code-Generation-Pipeline-Incorporating-Various-LLMs</h1>

<h2>CodeAlpaca-20k Dataset</h2>
<p>I utilized the <a href="https://huggingface.co/datasets/sahil2801/CodeAlpaca-20k">CodeAlpaca-20k</a> dataset for this project.</p>

<h2>Large Language Models (LLMs)</h2>
<p>I employed four different types of Large Language Models (LLMs) from Hugging Face for this task. Here are the details along with their respective links:</p>

<ol>
    <h3>Mistral-7B-v0.1</h3>
    <p>Model Link: <a href="https://huggingface.co/mistralai/Mistral-7B-v0.1">Mistral 7B</a></p>
  </li>
  <li>
    <h3>TinyLlama</h3>
    <p>Model Link: <a href="https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v1.0">TinyLlama</a></p>
  </li>
    <li>
    <h3>Starling-LM-7B-alpha</h3>
    <p>Model Link: <a href="https://huggingface.co/berkeley-nest/Starling-LM-7B-alpha">Starling-LM-7B-alpha</a></p>
  </li>
    <li>
    <h3>Mistral-7B-Instruct-v0.2</h3>
    <p>Model Link: <a href="https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2">Mistral-7B-Instruct-v0.2</a></p>
  </li>
    </li>
    <li>
    <h3>OpenChat 3.5 1210</h3>
    <p>Model Link: <a href="https://huggingface.co/openchat/openchat-3.5-1210">OpenChat 3.5 1210</a></p>
  </li>
    <li>
    <h3>GPT2</h3>
    <p>Model Link: <a href="https://huggingface.co/docs/transformers/model_doc/gpt2">GPT2 Documentation</a></p>
  </li>
  <li>
    <h3>GPT2-Medium</h3>
    <p>Model Link: <a href="https://huggingface.co/openai-community/gpt2-medium">GPT2-Medium</a></p>
  </li>
  <li>
</ol>
